{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "active-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15.0, 6.0)\n",
    "pd.set_option('max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "abandoned-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sagemaker session \n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-switch",
   "metadata": {},
   "source": [
    "## Upload Trainings Data To S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "sensitive-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_since_registration</th>\n",
       "      <th>web</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>offer_type_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   age   income  reward  difficulty  duration  \\\n",
       "0      1  33.0  72000.0       5           5         5   \n",
       "1      1  33.0  72000.0       2          10        10   \n",
       "2      0   NaN      NaN       5           5         5   \n",
       "3      1  40.0  57000.0       5          20        10   \n",
       "4      1  40.0  57000.0       3           7         7   \n",
       "\n",
       "   days_since_registration  web  email  mobile  social  gender_M  gender_O  \\\n",
       "0                      461    1      1       1       1         1         0   \n",
       "1                      461    1      1       1       1         1         0   \n",
       "2                       92    1      1       1       1         0         0   \n",
       "3                      198    1      1       0       0         0         1   \n",
       "4                      198    1      1       1       1         0         1   \n",
       "\n",
       "   offer_type_discount  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read preprocessed data\n",
    "data = pd.read_csv('preprocessed_data.csv').drop(['person', 'offer'], axis=1).rename(columns = {'offer_completed': 'label'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "random-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (27878, 14)\n",
      "test shape:  (11948, 14)\n"
     ]
    }
   ],
   "source": [
    "# Make train test split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=0)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "separate-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to S3 \n",
    "data_dir = 'data'\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/starbucks_rewards'\n",
    "\n",
    "train.to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)\n",
    "test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hydraulic-library",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker/starbucks_rewards/test.csv\n",
      "sagemaker/starbucks_rewards/train.csv\n"
     ]
    }
   ],
   "source": [
    "# Check: Has the upload been successful?\n",
    "s3_client = boto3.client('s3')\n",
    "for obj in s3_client.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-identifier",
   "metadata": {},
   "source": [
    "## Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "turned-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpreprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StandardScaler\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mimpute\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SimpleImputer\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mensemble\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomForestClassifier\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomizedSearchCV\n",
      "\n",
      "\u001b[37m# Define hyperparameter space\u001b[39;49;00m\n",
      "HYPERPARAMETER_GRID = {\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mimputer__strategy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mmean\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmedian\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__bootstrap\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[34mTrue\u001b[39;49;00m, \u001b[34mFalse\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__max_depth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, \u001b[34m30\u001b[39;49;00m, \u001b[34m40\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m, \u001b[34m60\u001b[39;49;00m, \u001b[34m70\u001b[39;49;00m, \u001b[34m80\u001b[39;49;00m, \u001b[34m90\u001b[39;49;00m, \u001b[34m100\u001b[39;49;00m, \u001b[34mNone\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__max_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mauto\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33msqrt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__min_samples_leaf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m4\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__min_samples_split\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[34m2\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m],\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mrf__n_estimators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[34m200\u001b[39;49;00m, \u001b[34m400\u001b[39;49;00m, \u001b[34m600\u001b[39;49;00m, \u001b[34m800\u001b[39;49;00m, \u001b[34m1000\u001b[39;49;00m, \u001b[34m1200\u001b[39;49;00m, \u001b[34m1400\u001b[39;49;00m, \u001b[34m1600\u001b[39;49;00m, \u001b[34m1800\u001b[39;49;00m, \u001b[34m2000\u001b[39;49;00m]    \n",
      "}\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"Load model from the model_dir. This is the same model that is saved\u001b[39;49;00m\n",
      "\u001b[33m    in the main if statement.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# load using joblib\u001b[39;49;00m\n",
      "    model = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\n",
      "    \u001b[33m\"\"\"Predict probabilities of belonging to the positive class\"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    classes = model.classes_\n",
      "    pred_prob = model.predict_proba(input_data)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m pred_prob[:,np.argwhere(classes==\u001b[34m1\u001b[39;49;00m)].squeeze()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \u001b[33m\"\"\"This is the code that will be executed for model training. We train a sklearn\u001b[39;49;00m\n",
      "\u001b[33m    classifier and dump it to S3.\"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Set SageMaker parameters\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# Set model parameters\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n_iter\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m) \u001b[37m# number of cv runs\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Create args that holds all passed-in arguments\u001b[39;49;00m\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    \u001b[37m# Read in csv training file\u001b[39;49;00m\n",
      "    training_dir = args.data_dir\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Split dataframe into feature matrix and target vector\u001b[39;49;00m\n",
      "    X_train = train_data.iloc[:,\u001b[34m1\u001b[39;49;00m:] \u001b[37m# Labels are in the first column\u001b[39;49;00m\n",
      "    y_train = train_data.iloc[:,\u001b[34m0\u001b[39;49;00m]\n",
      "\n",
      "    \u001b[37m# Create pipeline\u001b[39;49;00m\n",
      "    pipeline = Pipeline([\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mimputer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, SimpleImputer()),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mscaler\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StandardScaler()),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mrf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, RandomForestClassifier(random_state=\u001b[34m0\u001b[39;49;00m))\n",
      "    ])\n",
      "    \n",
      "    \u001b[37m# Cross validate model\u001b[39;49;00m\n",
      "    cv = RandomizedSearchCV(\n",
      "        estimator=pipeline, \n",
      "        param_distributions=HYPERPARAMETER_GRID, \n",
      "        n_iter=args.n_iter,\n",
      "        random_state=\u001b[34m0\u001b[39;49;00m,\n",
      "        n_jobs=-\u001b[34m1\u001b[39;49;00m\n",
      "    )\n",
      "    \n",
      "    cv.fit(X_train, y_train)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCross validation finished\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mBest params: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, cv.best_params_)\n",
      "\n",
      "    \u001b[37m# Save the trained model\u001b[39;49;00m\n",
      "    joblib.dump(cv.best_estimator_, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "incredible-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to save model artifacts\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "# Instantiate the sklearn estimator\n",
    "estimator = SKLearn(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    entry_point='train.py',\n",
    "    source_dir='src',\n",
    "    py_version='py3',\n",
    "    framework_version='0.23-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "protected-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-27 12:39:15 Starting - Starting the training job...\n",
      "2021-02-27 12:39:17 Starting - Launching requested ML instancesProfilerReport-1614429555: InProgress\n",
      "......\n",
      "2021-02-27 12:40:31 Starting - Preparing the instances for training......\n",
      "2021-02-27 12:41:39 Downloading - Downloading input data...\n",
      "2021-02-27 12:42:12 Training - Downloading the training image..\u001b[34m2021-02-27 12:42:28,923 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-02-27 12:42:28,925 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-27 12:42:28,935 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2021-02-27 12:42:32 Training - Training image download completed. Training in progress.\u001b[34m2021-02-27 12:42:36,573 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-27 12:42:36,586 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-27 12:42:36,599 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-27 12:42:36,609 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-02-27-12-39-15-309\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-157639178476/sagemaker-scikit-learn-2021-02-27-12-39-15-309/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-157639178476/sagemaker-scikit-learn-2021-02-27-12-39-15-309/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-02-27-12-39-15-309\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-157639178476/sagemaker-scikit-learn-2021-02-27-12-39-15-309/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\u001b[0m\n",
      "\u001b[34mCross validation finished\u001b[0m\n",
      "\u001b[34mBest params:  {'rf__n_estimators': 2000, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__max_depth': 50, 'rf__bootstrap': True, 'imputer__strategy': 'median'}\u001b[0m\n",
      "\u001b[34m2021-02-27 12:50:23,113 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-02-27 12:50:39 Uploading - Uploading generated training model\n",
      "2021-02-27 12:51:19 Completed - Training job completed\n",
      "ProfilerReport-1614429555: NoIssuesFound\n",
      "Training seconds: 573\n",
      "Billable seconds: 573\n",
      "CPU times: user 1.67 s, sys: 120 ms, total: 1.79 s\n",
      "Wall time: 12min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train estimator on S3 training data\n",
    "estimator.fit({'train': train_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-november",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "combined-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 341 ms, sys: 15.6 ms, total: 356 ms\n",
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Deploy model and assign to variable for making predictions\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-processor",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "romance-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test data into feature matrix and target vector\n",
    "X_test = test.iloc[:,1:]\n",
    "y_test = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "secure-desert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42470315, 0.64550168, 0.02014354, ..., 0.062982  , 0.23421987,\n",
       "       0.96312812])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = predictor.predict(X_test)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "universal-security",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308796388934323"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-birth",
   "metadata": {},
   "source": [
    "## Application: Decide Which Offer A Customer Should Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "french-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = [\n",
    "    {\n",
    "        'id': '0009655768c64bdeb2e877511632db8f',\n",
    "        'age': 33,\n",
    "        'gender': 'M',\n",
    "        'income': 72000,\n",
    "        'days_since_registration': 461}, \n",
    "    {\n",
    "        'id': '00116118485d4dfda04fdbaba9a87b5c',\n",
    "        'age': np.nan,\n",
    "        'gender': np.nan,\n",
    "        'income': np.nan,\n",
    "        'days_since_registration': 92}, \n",
    "    {\n",
    "        'id': '0011e0d4e6b944f998e987f904e8c1e5',\n",
    "        'age': 40,\n",
    "        'gender': 'O',\n",
    "        'income': 57000,\n",
    "        'days_since_registration': 198}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "global-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers = [\n",
    "    {\n",
    "        'id': 'ae264e3637204a6fb9bb56bc8210ddfd',\n",
    "        'type': 'bogo',\n",
    "        'web': 1,\n",
    "        'email': 1,\n",
    "        'social': 1,\n",
    "        'mobile': 0,\n",
    "        'reward': 10,\n",
    "        'difficulty': 10,\n",
    "        'duration': 7}, \n",
    "    {\n",
    "        'id': 'f19421c1d4aa40978ebb69ca19b0e20d',\n",
    "        'type': 'bogo',\n",
    "        'web': 1,\n",
    "        'email': 1,\n",
    "        'social': 1,\n",
    "        'mobile': 1,\n",
    "        'reward': 5,\n",
    "        'difficulty': 5,\n",
    "        'duration': 5}, \n",
    "    {\n",
    "        'id': '0b1e1539f2cc45b7b9fa7c272da2e1d7',\n",
    "        'type': 'discount',\n",
    "        'web': 1,\n",
    "        'email': 1,\n",
    "        'social': 0,\n",
    "        'mobile': 0,\n",
    "        'reward': 5,\n",
    "        'difficulty': 20,\n",
    "        'duration': 10}  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "median-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_success_probabilities(customers, offers):\n",
    "    \"\"\"Calculates for each customer the success probabilities of various offers\"\"\"\n",
    "    \n",
    "    probas = {}\n",
    "    for customer in customers:\n",
    "        probas[customer['id']] = {}\n",
    "\n",
    "        for offer in offers:\n",
    "            pred = predictor.predict([[\n",
    "                customer['age'], customer['income'], offer['reward'], offer['difficulty'], offer['duration'], \n",
    "                customer['days_since_registration'], offer['web'], offer['email'], offer['mobile'], offer['social'], \n",
    "                (1 if customer['gender']=='M' else 0), (1 if customer['gender']=='O' else 0), (1 if offer['type']=='discount' else 0)\n",
    "            ]])\n",
    "            probas[customer['id']][offer['id']] = float(pred.squeeze())\n",
    "            \n",
    "    return probas\n",
    "\n",
    "def get_best_offer_for_customer(probas):\n",
    "    \"\"\"Infers best offer for customer from success probabilities\"\"\"\n",
    "    \n",
    "    choices = {}\n",
    "    for customer in probas.keys():\n",
    "        \n",
    "        best_offer = None\n",
    "        best_proba = 0\n",
    "        for offer_id, proba in probas[customer].items():\n",
    "            if proba > best_proba:\n",
    "                best_offer = offer_id\n",
    "                best_proba = proba\n",
    "            \n",
    "        choices[customer] = best_offer\n",
    "        \n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "sophisticated-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0009655768c64bdeb2e877511632db8f': {'0b1e1539f2cc45b7b9fa7c272da2e1d7': 0.9426955139133467,\n",
      "                                      'ae264e3637204a6fb9bb56bc8210ddfd': 0.5648851131888629,\n",
      "                                      'f19421c1d4aa40978ebb69ca19b0e20d': 0.9340771182491163},\n",
      " '00116118485d4dfda04fdbaba9a87b5c': {'0b1e1539f2cc45b7b9fa7c272da2e1d7': 0.053495241758556036,\n",
      "                                      'ae264e3637204a6fb9bb56bc8210ddfd': 0.02977202504887236,\n",
      "                                      'f19421c1d4aa40978ebb69ca19b0e20d': 0.10867103658455653},\n",
      " '0011e0d4e6b944f998e987f904e8c1e5': {'0b1e1539f2cc45b7b9fa7c272da2e1d7': 0.68744225190439,\n",
      "                                      'ae264e3637204a6fb9bb56bc8210ddfd': 0.5578886429082346,\n",
      "                                      'f19421c1d4aa40978ebb69ca19b0e20d': 0.6036967331975791}}\n"
     ]
    }
   ],
   "source": [
    "probas = get_success_probabilities(customers, offers)\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "steady-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0009655768c64bdeb2e877511632db8f': '0b1e1539f2cc45b7b9fa7c272da2e1d7',\n",
      " '00116118485d4dfda04fdbaba9a87b5c': 'f19421c1d4aa40978ebb69ca19b0e20d',\n",
      " '0011e0d4e6b944f998e987f904e8c1e5': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}\n"
     ]
    }
   ],
   "source": [
    "choices = get_best_offer_for_customer(probas)\n",
    "pprint.pprint(choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-waters",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "remarkable-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
